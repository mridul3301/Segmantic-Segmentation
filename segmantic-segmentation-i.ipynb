{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Import","metadata":{}},{"cell_type":"markdown","source":"Dataset : https://www.kaggle.com/datasets/humansintheloop/semantic-segmentation-of-aerial-imagery","metadata":{}},{"cell_type":"code","source":"!pip install patchify","metadata":{"execution":{"iopub.status.busy":"2023-09-04T16:10:17.009633Z","iopub.execute_input":"2023-09-04T16:10:17.010119Z","iopub.status.idle":"2023-09-04T16:10:33.220623Z","shell.execute_reply.started":"2023-09-04T16:10:17.010083Z","shell.execute_reply":"2023-09-04T16:10:33.219488Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting patchify\n  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from patchify) (1.23.5)\nInstalling collected packages: patchify\nSuccessfully installed patchify-0.2.3\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install segmentation_models_pytorch","metadata":{"execution":{"iopub.status.busy":"2023-09-04T16:38:38.549510Z","iopub.execute_input":"2023-09-04T16:38:38.550010Z","iopub.status.idle":"2023-09-04T16:38:58.730449Z","shell.execute_reply.started":"2023-09-04T16:38:38.549955Z","shell.execute_reply":"2023-09-04T16:38:58.729200Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Collecting segmentation_models_pytorch\n  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.15.1+cpu)\nCollecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: timm==0.9.2 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.9.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (4.65.0)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (9.5.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.0.0+cpu)\nCollecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch)\n  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation_models_pytorch) (0.16.4)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation_models_pytorch) (0.3.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.31.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2023.6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (21.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2023.5.7)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\nBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=ff837d2148a69a59b8bcb4054709e139191ab02dbea80fd1c2ef37fd36d2fb20\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60966 sha256=cd47b43f8e5f3b1126eaefaad02610f3f3a8eb353501020e9a0b16f7311f4874\n  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\nSuccessfully built efficientnet-pytorch pretrainedmodels\nInstalling collected packages: munch, efficientnet-pytorch, pretrainedmodels, segmentation_models_pytorch\nSuccessfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport re\nfrom pathlib import Path\nimport numpy as np\nfrom patchify import patchify\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2023-09-04T16:10:33.224464Z","iopub.execute_input":"2023-09-04T16:10:33.225048Z","iopub.status.idle":"2023-09-04T16:10:33.237036Z","shell.execute_reply.started":"2023-09-04T16:10:33.224950Z","shell.execute_reply":"2023-09-04T16:10:33.235966Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2\nimport segmentation_models_pytorch as smp\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-09-04T16:39:09.401866Z","iopub.execute_input":"2023-09-04T16:39:09.402531Z","iopub.status.idle":"2023-09-04T16:39:09.410813Z","shell.execute_reply.started":"2023-09-04T16:39:09.402454Z","shell.execute_reply":"2023-09-04T16:39:09.408634Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Create patches","metadata":{}},{"cell_type":"code","source":"def create_folder():\n    FOLDERS = ['train','val','test']\n    \n    for folder in FOLDERS:\n        if not os.path.exists(folder):\n            folder_imgs = f\"{folder}/images\"\n            folder_msks = f\"{folder}/masks\"\n            os.makedirs(folder_imgs) if not os.path.exists(folder_imgs) else print('folder already exists')\n            os.makedirs(folder_msks) if not os.path.exists(folder_msks) else print('folder already exists')","metadata":{"execution":{"iopub.status.busy":"2023-09-04T16:10:36.769718Z","iopub.execute_input":"2023-09-04T16:10:36.770484Z","iopub.status.idle":"2023-09-04T16:10:36.778228Z","shell.execute_reply.started":"2023-09-04T16:10:36.770445Z","shell.execute_reply":"2023-09-04T16:10:36.776718Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"create_folder()","metadata":{"execution":{"iopub.status.busy":"2023-09-04T16:10:36.779458Z","iopub.execute_input":"2023-09-04T16:10:36.779858Z","iopub.status.idle":"2023-09-04T16:10:36.795948Z","shell.execute_reply.started":"2023-09-04T16:10:36.779827Z","shell.execute_reply":"2023-09-04T16:10:36.794405Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Create Patches","metadata":{}},{"cell_type":"code","source":"def create_patches(src, dest_path):\n    path_split = os.path.split(src)\n    tile_num = re.findall(r'\\d+', path_split[0])\n    image = Image.open(src)\n    image = np.asarray(image)\n    if len(image.shape) > 2:\n        patches = patchify(image, (320, 320, 3), step = 300)\n        file_name_wo_ext = Path(src).stem\n        for i in range(patches.shape[0]):\n            for j in range(patches.shape[1]):\n                patch = patches[i, j, 0]\n                num = i * patches.shape[1] + j\n                patch = Image.fromarray(patch)\n                patch.save(f\"{dest_path}/{file_name_wo_ext}_tile_{tile_num}_patch_{num}.png\")\n                ","metadata":{"execution":{"iopub.status.busy":"2023-09-04T16:10:36.797736Z","iopub.execute_input":"2023-09-04T16:10:36.798135Z","iopub.status.idle":"2023-09-04T16:10:36.813414Z","shell.execute_reply.started":"2023-09-04T16:10:36.798100Z","shell.execute_reply":"2023-09-04T16:10:36.811801Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for path_name, _, file_name in os.walk('/kaggle/input/semantic-segmentation-of-aerial-imagery/Semantic segmentation dataset'):\n    for f in file_name:\n        print(f)\n        if f != 'classes.json':\n            path_split = os.path.split(path_name)\n            tile_num = re.findall(r'\\d+',path_split[0])[0]\n            img_type = path_split[1]\n            \n            if tile_num == '3':\n                target_folder_imgs = 'val'\n                target_foler_masks = 'val'\n            elif tile_num == '1':\n                target_folder_imgs = 'test'\n                target_foler_masks = 'test'\n            elif tile_num in ['4', '5', '6', '7', '8']:\n                target_folder_imgs = 'train'\n                target_foler_masks = 'train'\n                \n            # copy all images\n            src = os.path.join(path_name, f)\n            file_name_wo_ext = Path(src).stem\n            \n            # Check if file exists in images and masks\n            img_file = f\"{path_split[0]}/images/{file_name_wo_ext}.jpg\"\n            mask_file = f\"{path_split[0]}/masks/{file_name_wo_ext}.png\"\n            \n            if os.path.exists(img_file) and os.path.exists(mask_file):\n                if img_type == 'images':\n                    dest = os.path.join(target_folder_imgs, img_type)\n                    create_patches(src, dest)\n                \n                if img_type == 'masks':\n                    dest = os.path.join(target_foler_masks, img_type)\n                    create_patches(src, dest)                ","metadata":{"execution":{"iopub.status.busy":"2023-09-04T16:10:36.815470Z","iopub.execute_input":"2023-09-04T16:10:36.815865Z","iopub.status.idle":"2023-09-04T16:11:23.011295Z","shell.execute_reply.started":"2023-09-04T16:10:36.815834Z","shell.execute_reply":"2023-09-04T16:11:23.010082Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"classes.json\nimage_part_002.jpg\nimage_part_006.jpg\nimage_part_005.jpg\nimage_part_003.jpg\nimage_part_004.jpg\nimage_part_007.jpg\nimage_part_009.jpg\nimage_part_008.jpg\nimage_part_001.jpg\nimage_part_001.png\nimage_part_003.png\nimage_part_006.png\nimage_part_002.png\nimage_part_008.png\nimage_part_007.png\nimage_part_009.png\nimage_part_005.png\nimage_part_004.png\nimage_part_002.jpg\nimage_part_006.jpg\nimage_part_005.jpg\nimage_part_003.jpg\nimage_part_004.jpg\nimage_part_007.jpg\nimage_part_009.jpg\nimage_part_008.jpg\nimage_part_001.jpg\nimage_part_001.png\nimage_part_003.png\nimage_part_006.png\nimage_part_002.png\nimage_part_008.png\nimage_part_007.png\nimage_part_009.png\nimage_part_005.png\nimage_part_004.png\nimage_part_002.jpg\nimage_part_006.jpg\nimage_part_005.jpg\nimage_part_003.jpg\nimage_part_004.jpg\nimage_part_007.jpg\nimage_part_009.jpg\nimage_part_008.jpg\nimage_part_001.jpg\nimage_part_001.png\nimage_part_003.png\nimage_part_006.png\nimage_part_002.png\nimage_part_008.png\nimage_part_007.png\nimage_part_009.png\nimage_part_005.png\nimage_part_004.png\nimage_part_002.jpg\nimage_part_006.jpg\nimage_part_005.jpg\nimage_part_003.jpg\nimage_part_004.jpg\nimage_part_007.jpg\nimage_part_009.jpg\nimage_part_008.jpg\nimage_part_001.jpg\nimage_part_001.png\nimage_part_003.png\nimage_part_006.png\nimage_part_002.png\nimage_part_008.png\nimage_part_007.png\nimage_part_009.png\nimage_part_005.png\nimage_part_004.png\nimage_part_002.jpg\nimage_part_006.jpg\nimage_part_005.jpg\nimage_part_003.jpg\nimage_part_004.jpg\nimage_part_007.jpg\nimage_part_009.jpg\nimage_part_008.jpg\nimage_part_001.jpg\nimage_part_001.png\nimage_part_003.png\nimage_part_006.png\nimage_part_002.png\nimage_part_008.png\nimage_part_007.png\nimage_part_009.png\nimage_part_005.png\nimage_part_004.png\nimage_part_002.jpg\nimage_part_006.jpg\nimage_part_005.jpg\nimage_part_003.jpg\nimage_part_004.jpg\nimage_part_007.jpg\nimage_part_009.jpg\nimage_part_008.jpg\nimage_part_001.jpg\nimage_part_001.png\nimage_part_003.png\nimage_part_006.png\nimage_part_002.png\nimage_part_008.png\nimage_part_007.png\nimage_part_009.png\nimage_part_005.png\nimage_part_004.png\nimage_part_002.jpg\nimage_part_006.jpg\nimage_part_005.jpg\nimage_part_003.jpg\nimage_part_004.jpg\nimage_part_007.jpg\nimage_part_009.jpg\nimage_part_008.jpg\nimage_part_001.jpg\nimage_part_001.png\nimage_part_003.png\nimage_part_006.png\nimage_part_002.png\nimage_part_008.png\nimage_part_007.png\nimage_part_009.png\nimage_part_005.png\nimage_part_004.png\nimage_part_002.jpg\nimage_part_006.jpg\nimage_part_005.jpg\nimage_part_003.jpg\nimage_part_004.jpg\nimage_part_007.jpg\nimage_part_009.jpg\nimage_part_008.jpg\nimage_part_001.jpg\nimage_part_001.png\nimage_part_003.png\nimage_part_006.png\nimage_part_002.png\nimage_part_008.png\nimage_part_007.png\nimage_part_009.png\nimage_part_005.png\nimage_part_004.png\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Create Dataset class","metadata":{}},{"cell_type":"code","source":"class SegmentationDataset(Dataset):\n    \n    def __init__(self, path_name) -> None:\n        super().__init__()\n        self.image_names = os.listdir(f\"{path_name}/images\")\n        self.image_paths = [f\"{path_name}/images/{i}\" for i in self.image_names]\n        self.mask_names = os.listdir(f\"{path_name}/masks\")\n        self.mask_paths = [f\"{path_name}/images/{i}\" for i in self.mask_names]\n        \n        # filter all images that do not exists in both folder\n        self.img_stem = [Path(i).stem for i in self.image_paths]\n        self.msk_stem = [Path(i).stem for i in self.mask_paths]\n        \n        self.img_msk_stem = set(self.img_stem) & set(self.msk_stem)\n        \n        self.image_paths = [i for i in self.image_paths if (Path(i).stem in self.img_msk_stem)]\n    \n    def __len__(self):\n        return len(self.img_msk_stem)\n    \n    def convert_mask(self, mask):\n        mask[mask == 155] = 0 # unlabelled\n        mask[mask == 44] = 1 # building\n        mask[mask == 91] = 2 # land\n        mask[mask == 171] = 3 # water\n        mask[mask == 172] = 4 # road\n        mask[mask == 212] = 5 # vegetation\n    \n    def __getitem__(self, index):\n        image = cv2.imread(self.image_paths[index])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        image = image.transpose((2, 0, 1))\n        mask = cv2.imread(self.mask_paths[index], 0)\n        mask = self.convert_mask(mask)\n        return image, mask\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-04T16:46:37.688723Z","iopub.execute_input":"2023-09-04T16:46:37.689240Z","iopub.status.idle":"2023-09-04T16:46:37.703308Z","shell.execute_reply.started":"2023-09-04T16:46:37.689197Z","shell.execute_reply":"2023-09-04T16:46:37.701926Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Modelling","metadata":{}},{"cell_type":"code","source":"DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2023-09-04T16:42:48.176270Z","iopub.execute_input":"2023-09-04T16:42:48.176706Z","iopub.status.idle":"2023-09-04T16:42:48.182624Z","shell.execute_reply.started":"2023-09-04T16:42:48.176667Z","shell.execute_reply":"2023-09-04T16:42:48.181360Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"DEVICE","metadata":{"execution":{"iopub.status.busy":"2023-09-04T16:42:53.459153Z","iopub.execute_input":"2023-09-04T16:42:53.459566Z","iopub.status.idle":"2023-09-04T16:42:53.468767Z","shell.execute_reply.started":"2023-09-04T16:42:53.459531Z","shell.execute_reply":"2023-09-04T16:42:53.467752Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'cpu'"},"metadata":{}}]},{"cell_type":"code","source":"EPOCHS = 10","metadata":{"execution":{"iopub.status.busy":"2023-09-04T16:43:03.175298Z","iopub.execute_input":"2023-09-04T16:43:03.175700Z","iopub.status.idle":"2023-09-04T16:43:03.181563Z","shell.execute_reply.started":"2023-09-04T16:43:03.175668Z","shell.execute_reply":"2023-09-04T16:43:03.180140Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 4","metadata":{"execution":{"iopub.status.busy":"2023-09-04T16:43:10.237431Z","iopub.execute_input":"2023-09-04T16:43:10.237881Z","iopub.status.idle":"2023-09-04T16:43:10.246293Z","shell.execute_reply.started":"2023-09-04T16:43:10.237843Z","shell.execute_reply":"2023-09-04T16:43:10.243455Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Create dataloader\ntrain_ds = SegmentationDataset(path_name = 'train')\ntrain_dataloader = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = True)\nval_ds = SegmentationDataset(path_name = 'val')\nval_dataloader = DataLoader(val_ds, batch_size = BATCH_SIZE, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T16:46:40.833321Z","iopub.execute_input":"2023-09-04T16:46:40.833746Z","iopub.status.idle":"2023-09-04T16:46:40.869334Z","shell.execute_reply.started":"2023-09-04T16:46:40.833712Z","shell.execute_reply":"2023-09-04T16:46:40.868046Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_ds[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-04T16:46:41.976029Z","iopub.execute_input":"2023-09-04T16:46:41.976508Z","iopub.status.idle":"2023-09-04T16:46:42.023228Z","shell.execute_reply.started":"2023-09-04T16:46:41.976461Z","shell.execute_reply":"2023-09-04T16:46:42.022125Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(array([[[101, 100,  98, ..., 193, 191, 187],\n         [106, 108, 107, ..., 191, 186, 181],\n         [110, 114, 113, ..., 182, 174, 180],\n         ...,\n         [205, 210, 211, ..., 193, 185, 162],\n         [208, 214, 210, ..., 183, 178, 153],\n         [206, 207, 202, ..., 193, 173, 137]],\n \n        [[ 83,  81,  79, ..., 200, 198, 194],\n         [ 87,  88,  87, ..., 198, 193, 188],\n         [ 89,  91,  90, ..., 189, 181, 187],\n         ...,\n         [213, 218, 219, ..., 199, 191, 168],\n         [216, 222, 218, ..., 191, 186, 161],\n         [214, 215, 210, ..., 203, 181, 147]],\n \n        [[ 79,  75,  73, ..., 210, 208, 204],\n         [ 81,  81,  80, ..., 208, 203, 198],\n         [ 84,  85,  84, ..., 199, 191, 197],\n         ...,\n         [224, 229, 230, ..., 211, 203, 180],\n         [227, 233, 229, ..., 204, 199, 174],\n         [225, 226, 221, ..., 215, 194, 159]]], dtype=uint8),\n None)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}