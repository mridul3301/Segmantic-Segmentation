{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ewD-Z4Cgq_2n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def double_conv(in_c, out_c):\n",
        "    conv = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size = 3),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Conv2d(out_c, out_c, kernel_size = 3),\n",
        "        nn.ReLU(inplace = True),\n",
        "    )\n",
        "\n",
        "    return conv"
      ],
      "metadata": {
        "id": "8FtJbQ--sDgi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_img(original_tensor, target_tensor):\n",
        "\n",
        "    target_size = target_tensor.size()[2]\n",
        "    original_size = original_tensor.size()[2]\n",
        "    delta = original_size - target_size\n",
        "    delta = delta//2\n",
        "    return original_tensor[:, :, delta:original_size-delta, delta:original_size-delta]"
      ],
      "metadata": {
        "id": "WoYHDdc2zq1g"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def up_transpose(in_channel, out_channel):\n",
        "    return nn.ConvTranspose2d(\n",
        "            in_channels = in_channel,\n",
        "            out_channels = out_channel,\n",
        "            kernel_size=2,\n",
        "            stride = 2)"
      ],
      "metadata": {
        "id": "KhcoHmJj1c8m"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nm0LgbJL1ukr"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride = 2)\n",
        "        self.down_conv1 = double_conv(1, 64)\n",
        "        self.down_conv2 = double_conv(64, 128)\n",
        "        self.down_conv3 = double_conv(128, 256)\n",
        "        self.down_conv4 = double_conv(256, 512)\n",
        "        self.down_conv5 = double_conv(512, 1024)\n",
        "\n",
        "        self.transpose_conv_1 = up_transpose(1024, 512)\n",
        "        self.up_conv_1 = double_conv(1024, 512)\n",
        "        self.transpose_conv_2 = up_transpose(512, 256)\n",
        "        self.up_conv_2 = double_conv(512, 256)\n",
        "        self.transpose_conv_3 = up_transpose(256, 128)\n",
        "        self.up_conv_3 = double_conv(256, 128)\n",
        "        self.transpose_conv_4 = up_transpose(128, 64)\n",
        "        self.up_conv_4 = double_conv(128, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(\n",
        "            in_channels = 64,\n",
        "            out_channels=2,\n",
        "            kernel_size = 1\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, image):\n",
        "\n",
        "        ## Encoder\n",
        "        print(f\"Shape of image is : {image.shape}\")\n",
        "        print(\"--------------------------------------------------------\")\n",
        "        x1 = self.down_conv1(image)\n",
        "        print(f\"Shape after first convolution : {x1.shape}\")\n",
        "        x2 = self.max_pool_2x2(x1)\n",
        "        print(f\"Shape after first maxpooling : {x2.shape}\")\n",
        "        print(\"--------------------------------------------------------\")\n",
        "        x3 = self.down_conv2(x2)\n",
        "        print(f\"Shape after second convolution : {x3.shape}\")\n",
        "        x4 = self.max_pool_2x2(x3)\n",
        "        print(f\"Shape after second maxpooling : {x4.shape}\")\n",
        "        print(\"--------------------------------------------------------\")\n",
        "        x5 = self.down_conv3(x4)\n",
        "        print(f\"Shape after third convolution : {x5.shape}\")\n",
        "        x6 = self.max_pool_2x2(x5)\n",
        "        print(f\"Shape after third maxpooling : {x6.shape}\")\n",
        "        print(\"--------------------------------------------------------\")\n",
        "        x7 = self.down_conv4(x6)\n",
        "        print(f\"Shape after fourth convolution : {x7.shape}\")\n",
        "        x8 = self.max_pool_2x2(x7)\n",
        "        print(f\"Shape after fourth maxpooling : {x8.shape}\")\n",
        "        print(\"--------------------------------------------------------\")\n",
        "        x9 = self.down_conv5(x8)\n",
        "        print(f\"Shape after fifth convolution : {x9.shape}\")\n",
        "        print(\"We reached the end of Encoder.\")\n",
        "        print(\"--------------------------------------------------------\")\n",
        "\n",
        "        ## Decoder\n",
        "        print(f\"Shape of input to decoder is : {x9.shape}\")\n",
        "        i1 = self.transpose_conv_1(x9)\n",
        "        print(f\"Shape after first transpose convolution is : {i1.shape}\")\n",
        "        print(\"--------------------------------------------------------\")\n",
        "        c1 = crop_img(x7, i1)\n",
        "        print(f\"Shape of residual before cropping : {x7.shape}\")\n",
        "        print(f\"Shape of residual after cropping : {c1.shape}\")\n",
        "        print(f\"Shape before residual connection is : {i1.shape}\")\n",
        "        r1 = torch.cat([i1, c1], 1)\n",
        "        print(f\"Shape after residual connection : {r1.shape}\")\n",
        "        y1 = self.up_conv_1(r1)\n",
        "        print(f\"Shape after first up convolution : {y1.shape}\")\n",
        "        print(\"--------------------------------------------------------\")\n",
        "        i2 = self.transpose_conv_2(y1)\n",
        "        c2 = crop_img(x5, i2)\n",
        "        print(f\"Shape of residual before cropping : {x5.shape}\")\n",
        "        print(f\"Shape of residual after cropping : {c2.shape}\")\n",
        "        print(f\"Shape before residual connection is : {i2.shape}\")\n",
        "        r2 = torch.cat([i2, c2], 1)\n",
        "        print(f\"Shape after residual connection : {r2.shape}\")\n",
        "        y2 = self.up_conv_2(r2)\n",
        "        print(f\"Shape after second up convolution : {y2.shape}\")\n",
        "        print(\"--------------------------------------------------------\")\n",
        "        i3 = self.transpose_conv_3(y2)\n",
        "        c3 = crop_img(x3, i3)\n",
        "        print(f\"Shape of residual before cropping : {x3.shape}\")\n",
        "        print(f\"Shape of residual after cropping : {c3.shape}\")\n",
        "        print(f\"Shape before residual connection is : {i3.shape}\")\n",
        "        r3 = torch.cat([i3, c3], 1)\n",
        "        print(f\"Shape after residual connection : {r3.shape}\")\n",
        "        y3 = self.up_conv_3(r3)\n",
        "        print(f\"Shape after third up convolution : {y3.shape}\")\n",
        "        print(\"--------------------------------------------------------\")\n",
        "        i4 = self.transpose_conv_4(y3)\n",
        "        c4 = crop_img(x1, i4)\n",
        "        print(f\"Shape of residual before cropping : {x4.shape}\")\n",
        "        print(f\"Shape of residual after cropping : {c4.shape}\")\n",
        "        print(f\"Shape before residual connection is : {i4.shape}\")\n",
        "        r4 = torch.cat([i4, c4], 1)\n",
        "        print(f\"Shape after residual connection : {r4.shape}\")\n",
        "        y4 = self.up_conv_4(r4)\n",
        "        print(f\"Shape after third up convolution : {y4.shape}\")\n",
        "        print(\"--------------------------------------------------------\")\n",
        "        out = self.out(y4)\n",
        "        print(f\"Output shape : {out.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DQpk6UtCrTS1"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.rand((1, 1, 572, 572))\n",
        "print(f\"Original Shape : {image.shape}\")\n",
        "model = UNet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PUPcUSIuazj",
        "outputId": "3b6e7af4-777f-41e1-e4d6-5e4451ba596b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Shape : torch.Size([1, 1, 572, 572])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model(image))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTmzn-keu3TL",
        "outputId": "e51c9a7c-8b95-42aa-d8a5-22160d55abc8"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of image is : torch.Size([1, 1, 572, 572])\n",
            "--------------------------------------------------------\n",
            "Shape after first convolution : torch.Size([1, 64, 568, 568])\n",
            "Shape after first maxpooling : torch.Size([1, 64, 284, 284])\n",
            "--------------------------------------------------------\n",
            "Shape after second convolution : torch.Size([1, 128, 280, 280])\n",
            "Shape after second maxpooling : torch.Size([1, 128, 140, 140])\n",
            "--------------------------------------------------------\n",
            "Shape after third convolution : torch.Size([1, 256, 136, 136])\n",
            "Shape after third maxpooling : torch.Size([1, 256, 68, 68])\n",
            "--------------------------------------------------------\n",
            "Shape after fourth convolution : torch.Size([1, 512, 64, 64])\n",
            "Shape after fourth maxpooling : torch.Size([1, 512, 32, 32])\n",
            "--------------------------------------------------------\n",
            "Shape after fifth convolution : torch.Size([1, 1024, 28, 28])\n",
            "We reached the end of Encoder.\n",
            "--------------------------------------------------------\n",
            "Shape of input to decoder is : torch.Size([1, 1024, 28, 28])\n",
            "Shape after first transpose convolution is : torch.Size([1, 512, 56, 56])\n",
            "--------------------------------------------------------\n",
            "Shape of residual before cropping : torch.Size([1, 512, 64, 64])\n",
            "Shape of residual after cropping : torch.Size([1, 512, 56, 56])\n",
            "Shape before residual connection is : torch.Size([1, 512, 56, 56])\n",
            "Shape after residual connection : torch.Size([1, 1024, 56, 56])\n",
            "Shape after first up convolution : torch.Size([1, 512, 52, 52])\n",
            "--------------------------------------------------------\n",
            "Shape of residual before cropping : torch.Size([1, 256, 136, 136])\n",
            "Shape of residual after cropping : torch.Size([1, 256, 104, 104])\n",
            "Shape before residual connection is : torch.Size([1, 256, 104, 104])\n",
            "Shape after residual connection : torch.Size([1, 512, 104, 104])\n",
            "Shape after second up convolution : torch.Size([1, 256, 100, 100])\n",
            "--------------------------------------------------------\n",
            "Shape of residual before cropping : torch.Size([1, 128, 280, 280])\n",
            "Shape of residual after cropping : torch.Size([1, 128, 200, 200])\n",
            "Shape before residual connection is : torch.Size([1, 128, 200, 200])\n",
            "Shape after residual connection : torch.Size([1, 256, 200, 200])\n",
            "Shape after third up convolution : torch.Size([1, 128, 196, 196])\n",
            "--------------------------------------------------------\n",
            "Shape of residual before cropping : torch.Size([1, 128, 140, 140])\n",
            "Shape of residual after cropping : torch.Size([1, 64, 392, 392])\n",
            "Shape before residual connection is : torch.Size([1, 64, 392, 392])\n",
            "Shape after residual connection : torch.Size([1, 128, 392, 392])\n",
            "Shape after third up convolution : torch.Size([1, 64, 388, 388])\n",
            "--------------------------------------------------------\n",
            "Output shape : torch.Size([1, 2, 388, 388])\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}